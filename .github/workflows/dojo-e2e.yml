name: e2e

on:
  push:
    branches: [main]
    paths:
      - "integrations/**"
      - "apps/dojo/**"
      - "middlewares/**"
      - "pnpm-lock.yaml"
      - "pnpm-workspace.yaml"
      - ".github/workflows/dojo-e2e.yml"
      - "sdks/python/**"
      - "sdks/typescript/**"
  pull_request:
    branches: [main]
    paths:
      - "apps/dojo/**"
      - "integrations/**"
      - "middlewares/**"
      - "pnpm-lock.yaml"
      - "pnpm-workspace.yaml"
      - ".github/workflows/dojo-e2e.yml"
      - "sdks/python/**"
      - "sdks/typescript/**"

jobs:
  check-generated-files:
    name: dojo / check-generated-files
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "22"

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10.13.1

      - name: Validate agentFilesMapper and regenerate files.json
        working-directory: apps/dojo
        run: pnpm generate-content-json

      - name: Check files.json is up to date
        working-directory: apps/dojo
        run: |
          if git diff --exit-code src/files.json > /dev/null; then
            echo "✅ No changes detected in dojo/src/files.json. Everything is up to date."
          else
            echo "❌ Detected changes in dojo/src/files.json."
            echo ""
            echo "The committed files.json doesn't match what would be generated."
            echo "Please run \`(p)npm run generate-content-json\` in the apps/dojo folder and commit the updated file."
            echo ""
            echo "The detected diff was as follows:"
            echo "::group::Diff for dojo/src/files.json"
            git diff src/files.json
            echo "::endgroup::"
            exit 1
          fi

  dojo:
    name: dojo / ${{ matrix.suite }}
    needs: check-generated-files
    runs-on: depot-ubuntu-24.04
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        include:
          - suite: a2a-middleware
            test_path: tests/a2aMiddlewareTests
            agent_dir: middlewares/a2a-middleware/examples
            agent_prepare: uv sync
            agent_processes:
              - name: a2a-buildings-management
                cmd: PORT=8011 uv run buildings_management.py
              - name: a2a-finance
                cmd: PORT=8012 uv run finance.py
              - name: a2a-it
                cmd: PORT=8013 uv run it.py
              - name: a2a-orchestrator
                cmd: PORT=8014 uv run orchestrator.py
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8011,tcp:localhost:8012,tcp:localhost:8013,tcp:localhost:8014
          - suite: adk-middleware
            test_path: tests/adkMiddlewareTests
            agent_dir: integrations/adk-middleware/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: adk-middleware
                cmd: PORT=8010 uv run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8010
          - suite: agno
            test_path: tests/agnoTests
            agent_dir: integrations/agno/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: agno
                cmd: PORT=8002 uv run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8002
          - suite: crew-ai
            test_path: tests/crewAITests
            agent_dir: integrations/crew-ai/python
            agent_prepare: poetry install
            agent_processes:
              - name: crew-ai
                cmd: PORT=8003 poetry run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8003
          - suite: langgraph-python
            test_path: tests/langgraphPythonTests
            agent_dir: integrations/langgraph/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: langgraph-platform-python
                cmd: PORT=8005 pnpx @langchain/langgraph-cli@latest dev --no-browser --host 127.0.0.1 --port 8005
            needs_langgraph_env: true
            wait_on: http://localhost:9999,tcp:localhost:8005
          - suite: langgraph-typescript
            test_path: tests/langgraphTypescriptTests
            agent_dir: integrations/langgraph/typescript/examples
            agent_prepare: pnpm install
            agent_processes:
              - name: langgraph-platform-typescript
                cmd: PORT=8006 pnpx @langchain/langgraph-cli@latest dev --no-browser --host 127.0.0.1 --port 8006
            needs_langgraph_env: true
            wait_on: http://localhost:9999,tcp:localhost:8006
          - suite: langgraph-fastapi
            test_path: tests/langgraphFastAPITests
            agent_dir: integrations/langgraph/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: langgraph-fastapi
                cmd: PORT=8004 uv run uvicorn agents.dojo:app --host 0.0.0.0 --port 8004
            needs_langgraph_env: true
            wait_on: http://localhost:9999,tcp:localhost:8004
          - suite: llama-index
            test_path: tests/llamaIndexTests
            agent_dir: integrations/llama-index/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: llama-index
                cmd: PORT=8007 uv run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8007
          - suite: mastra
            test_path: tests/mastraTests
            agent_dir: integrations/mastra/typescript/examples
            agent_prepare: pnpm install --no-frozen-lockfile
            agent_processes:
              - name: mastra
                cmd: PORT=8008 npm run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8008
          - suite: mastra-agent-local
            test_path: tests/mastraAgentLocalTests
            agent_dir: ""
            agent_prepare: ""
            agent_processes: []
            needs_langgraph_env: false
            wait_on: http://localhost:9999
          - suite: middleware-starter
            test_path: tests/middlewareStarterTests
            agent_dir: ""
            agent_prepare: ""
            agent_processes: []
            needs_langgraph_env: false
            wait_on: http://localhost:9999
          - suite: pydantic-ai
            test_path: tests/pydanticAITests
            agent_dir: integrations/pydantic-ai/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: pydantic-ai
                cmd: PORT=8009 uv run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8009
          - suite: server-starter
            test_path: tests/serverStarterTests
            agent_dir: integrations/server-starter/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: server-starter
                cmd: PORT=8000 uv run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8000
          - suite: server-starter-all
            test_path: tests/serverStarterAllFeaturesTests
            agent_dir: integrations/server-starter-all-features/python/examples
            agent_prepare: uv sync
            agent_processes:
              - name: server-starter-all
                cmd: PORT=8001 uv run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8001
          - suite: aws-strands
            test_path: tests/awsStrandsTests
            agent_dir: integrations/aws-strands/python/examples
            agent_prepare: poetry install
            agent_processes:
              - name: aws-strands
                cmd: PORT=8017 poetry run dev
            needs_langgraph_env: false
            wait_on: http://localhost:9999,tcp:localhost:8017
          # - suite: vercel-ai-sdk
          #   test_path: tests/vercelAISdkTests
          #   services: ["dojo"]
          #   wait_on: http://localhost:9999

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "22"

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10.13.1

      # Now that pnpm is available, cache its store to speed installs
      - name: Resolve pnpm store path
        id: pnpm-store
        run: echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Cache pnpm store
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      # Cache Python tool caches and virtual envs; restore only to avoid long saves
      - name: Cache Python dependencies (restore-only)
        if: ${{ contains(matrix.agent_prepare, 'uv ') || contains(matrix.agent_prepare, 'poetry ') || contains(toJson(matrix.agent_processes), 'uv run') || contains(toJson(matrix.agent_processes), 'poetry run') }}
        id: cache-python
        uses: actions/cache/restore@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/pypoetry
            ~/.cache/uv
            **/.venv
          key: ${{ runner.os }}-pydeps-${{ hashFiles('**/poetry.lock', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pydeps-

      - name: Cache Next.js build
        uses: actions/cache@v4
        with:
          path: ${{ github.workspace }}/apps/dojo/.next/cache
          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.yaml') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}
          restore-keys: |
            ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.yaml') }}-

      - name: Install Poetry
        if: ${{ contains(matrix.agent_prepare, 'poetry ') || contains(toJson(matrix.agent_processes), 'poetry run') }}
        uses: snok/install-poetry@v1
        with:
          version: latest
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Install uv
        if: ${{ contains(matrix.agent_prepare, 'uv ') || contains(toJson(matrix.agent_processes), 'uv run') }}
        uses: astral-sh/setup-uv@v6

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Cache e2e dependencies
        id: cache-e2e-deps
        uses: actions/cache@v4
        with:
          path: |
            apps/dojo/e2e/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-dojo-e2e-deps-${{ hashFiles('pnpm-lock.yaml', 'apps/dojo/e2e/package.json') }}
          restore-keys: |
            ${{ runner.os }}-dojo-e2e-deps-

      - name: Install e2e dependencies
        if: ${{ steps.cache-e2e-deps.outputs.cache-hit != 'true' }}
        working-directory: apps/dojo/e2e
        run: |
          pnpm install

      - name: write langgraph env files
        working-directory: integrations/langgraph
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
        if: ${{ matrix.needs_langgraph_env }}
        run: |
          echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > python/examples/.env
          echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> python/examples/.env
          echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > typescript/examples/.env
          echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> typescript/examples/.env

      - name: Prepare dojo build
        run: npx nx run demo-viewer:build

      - name: Prepare selected agent
        if: ${{ matrix.agent_prepare != '' }}
        working-directory: ${{ matrix.agent_dir }}
        run: ${{ matrix.agent_prepare }}

      - name: Initialize process tracking
        shell: bash
        run: |
          set -euo pipefail
          PID_FILE="$RUNNER_TEMP/dojo-service-pids-${{ matrix.suite }}.txt"
          : > "$PID_FILE"
          echo "DOJO_PID_FILE=$PID_FILE" >> "$GITHUB_ENV"

      - name: Start dojo
        shell: bash
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          PORT: 9999
          AG2_URL: http://localhost:8018
          SERVER_STARTER_URL: http://localhost:8000
          SERVER_STARTER_ALL_FEATURES_URL: http://localhost:8001
          AGNO_URL: http://localhost:8002
          CREW_AI_URL: http://localhost:8003
          LANGGRAPH_FAST_API_URL: http://localhost:8004
          LANGGRAPH_PYTHON_URL: http://localhost:8005
          LANGGRAPH_TYPESCRIPT_URL: http://localhost:8006
          LLAMA_INDEX_URL: http://localhost:8007
          MASTRA_URL: http://localhost:8008
          PYDANTIC_AI_URL: http://localhost:8009
          ADK_MIDDLEWARE_URL: http://localhost:8010
          A2A_MIDDLEWARE_BUILDINGS_MANAGEMENT_URL: http://localhost:8011
          A2A_MIDDLEWARE_FINANCE_URL: http://localhost:8012
          A2A_MIDDLEWARE_IT_URL: http://localhost:8013
          A2A_MIDDLEWARE_ORCHESTRATOR_URL: http://localhost:8014
          AWS_STRANDS_URL: http://localhost:8017
          NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE: cpkdojo.local___CopilotKit Feature Viewer
        run: |
          set -euo pipefail
          nohup pnpm run start >/dev/null 2>&1 &
          echo "$!|dojo" >> "$DOJO_PID_FILE"

      - name: Start selected agent
        if: ${{ toJson(matrix.agent_processes) != '[]' }}
        shell: bash
        working-directory: ${{ matrix.agent_dir }}
        env:
          AGENT_PROCESSES: ${{ toJson(matrix.agent_processes) }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: |
          set -euo pipefail

          while IFS=$'\t' read -r name cmd; do
            [[ -z "$name" || -z "$cmd" ]] && continue
            echo "Starting $name"
            nohup bash -lc "$cmd" >/dev/null 2>&1 &
            echo "$!|$name" >> "$DOJO_PID_FILE"
          done < <(echo "$AGENT_PROCESSES" | jq -r '.[] | [.name, .cmd] | @tsv')

      - name: Debug startup probe (langgraph-fastapi)
        if: ${{ matrix.suite == 'langgraph-fastapi' }}
        shell: bash
        run: |
          set -euo pipefail
          PID_FILE="$RUNNER_TEMP/dojo-service-pids-${{ matrix.suite }}.txt"
          echo "Startup probe for langgraph-fastapi"

          sleep 10

          if [[ -f "$PID_FILE" ]]; then
            while IFS='|' read -r pid name; do
              [[ -z "$pid" || -z "$name" ]] && continue
              if kill -0 "$pid" 2>/dev/null; then
                echo "Process alive: $name ($pid)"
              else
                echo "Process not alive: $name ($pid)"
              fi
            done < "$PID_FILE"
          else
            echo "PID file not found: $PID_FILE"
          fi

          echo "Open ports snapshot:"
          ss -ltnp | grep -E ':9999|:8004' || true

          if ! ss -ltn | grep -q ':8004'; then
            echo "langgraph-fastapi is not listening on :8004 after startup probe"
            exit 1
          fi

      - name: Wait for services
        shell: bash
        env:
          WAIT_ON_TARGETS: ${{ matrix.wait_on }}
        run: |
          set -euo pipefail
          IFS=',' read -ra TARGETS <<< "$WAIT_ON_TARGETS"
          pnpm dlx wait-on --timeout 300000 "${TARGETS[@]}"

      - name: Run tests – ${{ matrix.suite }}
        working-directory: apps/dojo/e2e
        env:
          BASE_URL: http://localhost:9999
          PLAYWRIGHT_SUITE: ${{ matrix.suite }}
        run: |
          pnpm test -- ${{ matrix.test_path }}

      - name: Stop dojo and selected agents
        if: always()
        shell: bash
        run: |
          set +e
          PID_FILE="$RUNNER_TEMP/dojo-service-pids-${{ matrix.suite }}.txt"
          if [[ -f "$PID_FILE" ]]; then
            while IFS='|' read -r pid name; do
              if [[ -n "$pid" ]] && kill -0 "$pid" 2>/dev/null; then
                echo "Stopping $name (pid $pid)"
                kill "$pid" 2>/dev/null || true
              fi
            done < "$PID_FILE"
          fi

      - name: Upload traces – ${{ matrix.suite }}
        if: always() # Uploads artifacts even if tests fail
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.suite }}-playwright-traces
          path: |
            apps/dojo/e2e/test-results/${{ matrix.suite }}/**/*
            apps/dojo/e2e/playwright-report/**/*
          retention-days: 7
