---
title: "Connect to AG-UI"
description: "Connect AG-UI with existing protocols or custom solutions"
---

# Introduction

AG-UI provides a concise, event-driven protocol that lets any agent stream rich,
structured output to any client. In this quick-start you will:

1. Scaffold a new AG-UI integration that wraps **OpenAI's GPT-4o** model.
2. Register the integration with the **dojo**, a local web playground.
3. Stream responses from OpenAI through AG-UI's unified interface.

## Prerequisites

Make sure the following are available on your machine:

- [Node.js](https://nodejs.org/) **v16 or later**
- An **OpenAI API key**

### 1. Provide your OpenAI API key

```bash
# Set your OpenAI API key
export OPENAI_API_KEY=your-api-key-here
```

### 2. Install build utilities

You only have to do this once:

```bash
brew install protobuf
```

```bash
npm i turbo
```

```bash
curl -fsSL https://get.pnpm.io/install.sh | sh -
```

## Step 1 â€“ Scaffold the integration

Clone the repo and change into the TypeScript SDK:

```bash
git clone git@github.com:ag-ui-protocol/ag-ui.git
cd ag-ui/typescript-sdk
```

Copy the starter template:

```bash
cp -r integrations/starter integrations/openai
```

### Update metadata

Open `integrations/openai/package.json` and adjust the fields so they match the
new folder:

```json
{
  "name": "@ag-ui/openai",
  "private": false,
  "author": "Your Name <your-email@example.com>",
  "version": "0.0.1",

  ... rest of package.json
}
```

Update the class name inside `integrations/openai/src/index.ts`:

```ts
// change the name to OpenAIAgent
export class OpenAIAgent extends AbstractAgent {}
```

Finally, tell the dojo about the integration by adding it to
`apps/dojo/src/integrations.ts`:

```ts
import { configureIntegration } from "./types/integration"
import { StarterAgent } from "@ag-ui/starter"
export const integrations = [
  // ...

  configureIntegration({
    id: "openai",
    name: "OpenAI",
    features: ["agentic_chat"],
    agents: async () => {
      return {
        agentic_chat: new OpenAIAgent(),
      }
    },
  }),
]
```

## Step 2 â€“ Start the dojo

Install dependencies and launch the dev server:

```bash
# Install dependencies
pnpm install

# Compile the project and run the dojo
turbo run dev
```

Open [http://localhost:3000](http://localhost:3000) and choose **OpenAI** from
the drop-down. The stub agent replies with **Hello world!** for now.

The following code shows the minimal structure of that stub agent
(`StarterAgent`):

```ts
// integrations/openai/src/index.ts
import {
  AbstractAgent,
  BaseEvent,
  EventType,
  RunAgentInput,
} from "@ag-ui/client"
import { Observable } from "rxjs"

export class OpenAIAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = Date.now().toString()
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
      } as any)

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      observer.complete()
    })
  }
}
```

## Step 3 â€“ Bridge OpenAI with AG-UI

To turn the stub into a real agent we will stream completions from OpenAI.

### Install the OpenAI SDK

```bash
pnpm install openai
```

### AG-UI recap

An AG-UI agent extends `AbstractAgent` and emits a sequence of events to signal:

- lifecycle (`RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`)
- content (`TEXT_MESSAGE_*`, `TOOL_CALL_*`, â€¦)

### Implement the streaming agent

```typescript
// integrations/openai/src/index.ts
import {
  AbstractAgent,
  RunAgentInput,
  EventType,
  BaseEvent,
} from "@ag-ui/client"
import { Observable } from "rxjs"

import { OpenAI } from "openai"

export class OpenAIAgent extends AbstractAgent {
  private openai: OpenAI

  constructor(openai?: OpenAI) {
    super()
    this.openai = openai ?? new OpenAI()
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      this.openai.chat.completions
        .create({
          model: "gpt-4o",
          stream: true,
          tools: input.tools.map((tool) => ({
            type: "function",
            function: {
              name: tool.name,
              description: tool.description,
              parameters: tool.parameters,
            },
          })),
          messages: input.messages.map((message) => ({
            role: message.role as any,
            content: message.content ?? "",
            ...(message.role === "assistant" && message.toolCalls
              ? {
                  tool_calls: message.toolCalls,
                }
              : {}),
            ...(message.role === "tool"
              ? { tool_call_id: message.toolCallId }
              : {}),
          })),
        })
        .then(async (response) => {
          const messageId = Date.now().toString()

          for await (const chunk of response) {
            if (chunk.choices[0].delta.content) {
              observer.next({
                type: EventType.TEXT_MESSAGE_CHUNK,
                messageId,
                delta: chunk.choices[0].delta.content,
              } as any)
            } else if (chunk.choices[0].delta.tool_calls) {
              let toolCall = chunk.choices[0].delta.tool_calls[0]

              observer.next({
                type: EventType.TOOL_CALL_CHUNK,
                toolCallId: toolCall.id,
                toolCallName: toolCall.function?.name,
                parentMessageId: messageId,
                delta: toolCall.function?.arguments,
              } as any)
            }
          }

          observer.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
          } as any)

          observer.complete()
        })
        .catch((error) => {
          observer.next({
            type: EventType.RUN_ERROR,
            message: error.message,
          } as any)

          observer.error(error)
        })
    })
  }
}
```

### What happens under the hood?

1. **Setup** â€“ create an OpenAI client and emit `RUN_STARTED`.
2. **Request** â€“ send the user's messages to `chat.completions` with
   `stream: true`.
3. **Streaming** â€“ forward each chunk as either `TEXT_MESSAGE_CHUNK` or
   `TOOL_CALL_CHUNK`.
4. **Finish** â€“ emit `RUN_FINISHED` (or `RUN_ERROR` on failure) and complete the
   observable.

## Step 4 â€“ Chat with the agent

Reload the dojo page and start typing. GPT-4o will now stream its answer, word
by word.

## Bridging AG-UI to any protocol

The pattern you just implementedâ€”translate inputs, forward streaming chunks,
emit AG-UI eventsâ€”works for virtually any backend:

- REST or GraphQL APIs
- WebSockets
- IoT protocols such as MQTT

## Connect your agent to a frontend

Tools like [CopilotKit](https://docs.copilotkit.ai) already understand AG-UI and
provide plug-and-play React components. Point them at your agent endpoint and
you get a full-featured chat UI out of the box.

## Contribute your integration

Did you build a custom adapter that others could reuse? We welcome community
contributions!

1. Fork the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui).
2. Add your package under `integrations/` and include minimal docs and tests.
3. Open a pull request describing your use-case and design decisions.

If you have questions, need feedback, or want to validate an idea first, start a
thread in the GitHub Discussions board:
<https://github.com/orgs/ag-ui-protocol/discussions>.

Your integration might ship in the next release and help the entire AG-UI
ecosystem grow.

## Conclusion

You now have a fully-functional AG-UI adapter for OpenAI and a local playground
to test it. From here you can:

- add tool calls to enrich the agent
- publish the integration to npm
- or bridge AG-UI to any other model or service you like.

Happy building! ðŸš€
