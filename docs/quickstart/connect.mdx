---
title: "Connect to AG-UI"
description: "Connect AG-UI with existing protocols or custom solutions"
---

In this tutorial, you'll learn how to create an agent that connects to
**OpenAI's API** and demonstrates how the Agent User Interaction Protocol
(AG-UI) can integrate seamlessly with any modern AI service. Let's get started.

## Prerequisites

Make sure to have the following:

- [Node.js](https://nodejs.org/) (v16 or later)
- An OpenAI API key

### Setting up OpenAI access

Before we start coding, make sure you have an OpenAI API key. You can get one by
signing up at [OpenAI's platform](https://platform.openai.com/).

Once you have your API key, set it as an environment variable:

```bash
# Set your OpenAI API key
export OPENAI_API_KEY=your-api-key-here
```

### Install the build tools

We will need `protoc`, `turbo` and `pnpm` installed.

```bash
brew install protobuf
```

```bash
npm i turbo
```

```bash
curl -fsSL https://get.pnpm.io/install.sh | sh -
```

## Setting up a new integration

We'll start by cloning the AG-UI repository.

```bash
git clone git@github.com:ag-ui-protocol/ag-ui.git
cd ag-ui/typescript-sdk
```

Next, we duplicate the starter integration by running:

```bash
cp -r integrations/starter integrations/openai
```

This will create a new integration called `openai` in the `integrations`
directory.

Next we need to update `integrations/openai/package.json` to match the name of
the directory, `@ag-ui/openai`. Also, we set `private` to `false`.

```json
{
  "name": "@ag-ui/openai",
  "private": false,
  "author": "Your Name <your-email@example.com>",
  "version": "0.0.1",

  ... rest of package.json
}
```

Then, we update the `integrations/openai/src/index.ts` and give it a matching
name:

```ts
// change the name to OpenAIAgent
export class OpenAIAgent extends AbstractAgent {}
```

Finally, we need to let the dojo know about our new integration. We do this by
adding it to the `integrations` array in `apps/dojo/src/integrations.ts`.

```ts
import { configureIntegration } from "./types/integration"
import { StarterAgent } from "@ag-ui/starter"
export const integrations = [
  // ...

  configureIntegration({
    id: "openai",
    name: "OpenAI",
    features: ["agentic_chat"],
    agents: async () => {
      return {
        agentic_chat: new OpenAIAgent(),
      }
    },
  }),
]
```

## Running the dojo

Now we can run the dojo, a web app for testing AG-UI agents and see our new
integration in action.

```bash
# Install dependencies
pnpm install

# Compile the project and run the dojo
turbo run dev
```

We can open the dojo at [http://localhost:3000](http://localhost:3000) and see
the integration we made by selecting "OpenAI" from the dropdown on the left.

When we try to chat with it, we should be greeted with a "Hello world!" message.

Next, we'll have a look at `integrations/openai/src/index.ts`. We will be
modifying this file to connect to OpenAI's API in a minute.

```ts
// integrations/openai/src/index.ts
import {
  AbstractAgent,
  BaseEvent,
  EventType,
  RunAgentInput,
} from "@ag-ui/client"
import { Observable } from "rxjs"

export class StarterAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = Date.now().toString()
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
      } as any)

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      observer.complete()
    })
  }
}
```

Our example contains the minimal structure of an AG-UI agent. We implement
`run()` and emit a series of events. First, we signal the start of a new run
(`RUN_STARTED`). Then, we emit a text message (`TEXT_MESSAGE_START` /
`TEXT_MESSAGE_CONTENT` / `TEXT_MESSAGE_END`). Finally, we signal the end of the
run (`RUN_FINISHED`).

## Bridge OpenAI with AG-UI

Now, let's build on this example by connecting to a simple ReAct agent based on
OpenAI's API.

Let's add OpenAI to the project:

```bash
pnpm install openai
```

### AG-UI Recap

The Agent User Interaction Protocol is a framework that lets you connect agents
to clients in a structured, event-driven way. Agents implement the
`AbstractAgent` class from `@ag-ui/client` and emit events for each piece of
content, progress, etc.

### Implementing OpenAI

We'll now modify the `CustomAgent` to:

1. Connect to OpenAI's API using their official Node.js SDK.
2. Send the user's messages to OpenAI.
3. Stream the response back, emitting AG-UI events for each chunk of text.

```typescript
// integrations/openai/src/index.ts
import {
  AbstractAgent,
  RunAgentInput,
  EventType,
  BaseEvent,
} from "@ag-ui/client"
import { Observable } from "rxjs"

import { OpenAI } from "openai"

export class CustomAgent extends AbstractAgent {
  private openai: OpenAI

  constructor(openai?: OpenAI) {
    super()
    this.openai = openai ?? new OpenAI()
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      this.openai.chat.completions
        .create({
          model: "gpt-4o",
          stream: true,
          tools: input.tools.map((tool) => ({
            type: "function",
            function: {
              name: tool.name,
              description: tool.description,
              parameters: tool.parameters,
            },
          })),
          messages: input.messages.map((message) => ({
            role: message.role as any,
            content: message.content ?? "",
            ...(message.role === "assistant" && message.toolCalls
              ? {
                  tool_calls: message.toolCalls,
                }
              : {}),
            ...(message.role === "tool"
              ? { tool_call_id: message.toolCallId }
              : {}),
          })),
        })
        .then(async (response) => {
          const messageId = Date.now().toString()

          for await (const chunk of response) {
            if (chunk.choices[0].delta.content) {
              observer.next({
                type: EventType.TEXT_MESSAGE_CHUNK,
                messageId,
                delta: chunk.choices[0].delta.content,
              } as any)
            } else if (chunk.choices[0].delta.tool_calls) {
              let toolCall = chunk.choices[0].delta.tool_calls[0]

              observer.next({
                type: EventType.TOOL_CALL_CHUNK,
                toolCallId: toolCall.id,
                toolCallName: toolCall.function?.name,
                parentMessageId: messageId,
                delta: toolCall.function?.arguments,
              } as any)
            }
          }

          observer.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
          } as any)

          observer.complete()
        })
        .catch((error) => {
          observer.next({
            type: EventType.RUN_ERROR,
            message: error.message,
          } as any)

          observer.error(error)
        })
    })
  }
}
```

### Explanation

1. **API Connection**: We create an OpenAI client using the official SDK and
   connect to OpenAI's API using your API key.

2. **Message Formatting**: We convert AG-UI messages to the format expected by
   OpenAI.

3. **Emitting Events**:

   - `RUN_STARTED` means the agent started processing the request.
   - `TEXT_MESSAGE_CHUNK` / `TOOL_CALL_CHUNK` let us conveniently stream the
     agent's textual response to the AG-UI pipeline.
   - `RUN_FINISHED` means this run is over.

4. **Stream Processing**:
   - We create a streaming completion request to OpenAI.
   - For each chunk of text received, we emit a `TEXT_MESSAGE_CONTENT` event.
   - After all chunks are processed, we finalize the message and run.

## Interacting with the agent

Now go to the [agentic chat](http://localhost:3000/feature/agentic_chat) demo
and type something in the chat input. You should see the agent responding using
OpenAI's gpt4o model.

## Bridging AG-UI to Any Protocol

This example demonstrates how to bridge AG-UI with an external AI service. The
key components are:

1. **AG-UI Agent Implementation**: Create a class that extends `AbstractAgent`
   and implements the `run` method.
2. **API Integration**: Connect to an external API (in this case, OpenAI).
3. **Message Formatting**: Convert between AG-UI's message format and the API's
   expected format.
4. **Event Streaming**: Stream the API responses back as AG-UI events.

You can apply this pattern to connect AG-UI to virtually any AI service or
protocol:

- HTTP/REST APIs
- WebSockets
- MQTT for IoT devices
- any other protocol

By following this pattern of creating protocol adapters around your AG-UI
agents, you can make your AI agents available through any AI service while
maintaining a consistent agent implementation.

## Conclusion

Congratulations! You've created an agent that connects to OpenAI's API and
bridges it to the Agent User Interaction Protocol. This tutorial demonstrates
how easy it is to adopt AG-UI with any modern AI serviceâ€”providing a consistent,
streaming interface for your applications regardless of the backend provider.

## Connect Your Agent to a Frontend

Now that you've built your AG-UI compatible agent, it's ready to be connected to
any frontend that supports the AG-UI protocol. One such frontend is
[CopilotKit](https://docs.copilotkit.ai), which provides a rich set of UI
components designed to work seamlessly with AG-UI agents.

To connect your agent to CopilotKit:

1. Follow the [CopilotKit documentation](https://docs.copilotkit.ai) to set up
   your frontend
2. Configure CopilotKit to connect to your agent using the AG-UI protocol
3. Enjoy a fully functioning chat UI with streaming responses!

With this setup, you can focus on building powerful agent capabilities while
leveraging existing UI components that understand the AG-UI protocol,
significantly reducing development time and effort.
